# training/utils/json_export.py
import os
import json
import numpy as np
from statistics import mean
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)


def convert_to_serializable(obj):
    """
    ğŸ”§ ä¿®å¤ï¼šå°†ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡è½¬ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
    """
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, defaultdict):
        return dict(obj)
    elif isinstance(obj, dict):
        return {k: convert_to_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [convert_to_serializable(v) for v in obj]
    else:
        return obj


def build_deploy_json_per_dataset(output_dir, all_details, all_metrics, task_id, model_version):
    """
    å¯¼å‡ºåŒ…å«æ¯ä¸ªæ•°æ®é›†çš„ï¼šæŒ‡æ ‡ã€æ›²çº¿/å›¾è·¯å¾„ã€è§†é¢‘èšåˆã€å…³é”®å¸§ç­‰

    ğŸ”§ ä¿®å¤ï¼šå¤„ç† JSON åºåˆ—åŒ–é—®é¢˜
    """
    try:
        payload = {
            'task_id': task_id,
            'model_version': model_version,
            'datasets': {}
        }

        for ds, det in all_details.items():
            logger.info(f"å¤„ç†æ•°æ®é›†: {ds}")

            # æ±‡æ€»æ¯ä¸ªè§†é¢‘çš„ç»Ÿè®¡
            videos = {}
            for vid, obj in det['video_map'].items():
                scores = [float(v) for v in obj['scores']]  # ç¡®ä¿æ˜¯ float

                if len(scores) == 0:
                    continue

                videos[vid] = {
                    'frame_count': len(scores),
                    'score_mean': float(np.mean(scores)),
                    'score_max': float(np.max(scores)),
                    'score_min': float(np.min(scores)),
                    'score_std': float(np.std(scores)),
                    'timeline_img': det['timeline_paths'].get(vid) if det.get('timeline_paths') else None,
                    'keyframes': det['keyframe_paths'].get(vid) if det.get('keyframe_paths') else None,
                }

            # è½¬æ¢ metricsï¼ˆç¡®ä¿æ‰€æœ‰å€¼å¯åºåˆ—åŒ–ï¼‰
            metrics_clean = convert_to_serializable(det['metrics'])

            payload['datasets'][ds] = {
                'metrics': metrics_clean,
                'video_count': len(videos),
                'frame_count': len(det['predictions']),
                'curves_dir': det['curves_dir'],
                'confusion_path': det['confusion_path'],
                'tsne_path': det['tsne_path'],
                'distribution_plot': det.get('distribution_plot'),  # æ–°å¢
                'videos': videos  # åªåŒ…å«å¿…è¦ä¿¡æ¯
            }

            logger.info(f"  è§†é¢‘æ•°: {len(videos)}, å¸§æ•°: {len(det['predictions'])}")

        # ä¿å­˜ JSON
        out_path = os.path.join(output_dir, f'benchmark_export_{task_id}.json')
        with open(out_path, 'w', encoding='utf-8') as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)

        logger.info(f"âœ… JSON å¯¼å‡ºæˆåŠŸ: {out_path}")
        return out_path

    except Exception as e:
        logger.error(f"âŒ JSON å¯¼å‡ºå¤±è´¥: {str(e)}", exc_info=True)
        raise


def build_detectionresponse_for_backend(all_details, task_id, model_version):
    """
    æ„é€ ä¸åç«¯åå®šçš„ DetectionResponseï¼ˆä»»åŠ¡çº§ï¼‰

    ğŸ”§ ä¼˜åŒ–ï¼šé€‰æ‹©æœ€å¯ç–‘çš„è§†é¢‘ä½œä¸ºä»£è¡¨
    """
    try:
        # é€‰æ‹©å…¨å±€"æœ€å¯ç–‘è§†é¢‘"
        best_vid, best_mean = None, -1.0
        best_ds = None

        for ds, det in all_details.items():
            for vid, obj in det['video_map'].items():
                scores = [float(v) for v in obj['scores']]
                if len(scores) == 0:
                    continue

                m = mean(scores)
                if m > best_mean:
                    best_mean = m
                    best_vid = vid
                    best_ds = ds

        fake_prob = max(0.0, min(1.0, best_mean))
        is_fake = fake_prob >= 0.5

        # æ„é€ å…³é”®å¸§
        kf_items = []
        if best_vid and best_ds:
            keyframes_data = all_details[best_ds].get('keyframe_paths', {}).get(best_vid, [])
            for item in keyframes_data[:5]:  # åªå–å‰5ä¸ª
                kf_items.append({
                    'frame_idx': -1,
                    'timestamp': 0.0,
                    'is_fake_score': float(item['score']),
                    'is_suspicious': True,
                    'reason': 'High fake probability',
                    'thumb_path': item['thumb_path']
                })

        # æ„é€ å“åº”
        detection = {
            'task_id': task_id,
            'is_fake': is_fake,
            'fake_probability': float(fake_prob),
            'confidence': float(max(0.5, fake_prob)),
            'key_frames': kf_items,
            'processing_time_ms': 0,
            'model_version': model_version,
            'created_at': '',

            # ç®€åŒ–çš„åˆ†æå­—æ®µ
            'summary': {
                'best_video_id': best_vid,
                'best_video_score': float(fake_prob),
                'total_videos': sum(len(det['video_map']) for det in all_details.values())
            }
        }

        return detection

    except Exception as e:
        logger.error(f"âŒ æ„é€  DetectionResponse å¤±è´¥: {str(e)}")
        raise


def post_result_to_backend(url, payload):
    """å‘é€ç»“æœåˆ°åç«¯"""
    import requests
    try:
        r = requests.post(url, json=payload, timeout=30)
        return (r.status_code == 200, r.text)
    except Exception as e:
        return (False, str(e))
